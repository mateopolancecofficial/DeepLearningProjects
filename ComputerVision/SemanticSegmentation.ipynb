{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SemanticSegmentation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMEGLMwFHVunvtsvnjn/VJ6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mateopolancecofficial/DeepLearningProjects/blob/main/ComputerVision/SemanticSegmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxpdoF0ZOzOY"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import cv2\n",
        "from scipy import io\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYksIcxfefCR",
        "outputId": "99b99099-9a44-4720-abe2-a7a0bc3c31d7"
      },
      "source": [
        "!git clone https://github.com/bearpaw/clothing-co-parsing.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'clothing-co-parsing'...\n",
            "remote: Enumerating objects: 4234, done.\u001b[K\n",
            "remote: Total 4234 (delta 0), reused 0 (delta 0), pack-reused 4234\u001b[K\n",
            "Receiving objects: 100% (4234/4234), 124.59 MiB | 47.04 MiB/s, done.\n",
            "Resolving deltas: 100% (1100/1100), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0937YkNhef6U",
        "outputId": "48e08053-8a81-429b-c62a-e796876e0d2c"
      },
      "source": [
        "!ls clothing-co-parsing/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "annotations  label_list.mat  photos\tshow_image_anno.m\n",
            "example.jpg  LICENSE\t     README.md\tshow_pixel_anno.m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wRKkdzOf4zp"
      },
      "source": [
        "img_path = \"./clothing-co-parsing/photos/\"\n",
        "mask_path = \"./clothing-co-parsing/annotations/pixel-level/\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wvev6Qb4ef_Q"
      },
      "source": [
        "def read_images(path):\n",
        "\n",
        "  images = []\n",
        "  for img_path in os.listdir(path):\n",
        "    url = os.path.join(path, img_path)\n",
        "    img = cv2.imread(url)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    images.append(tf.convert_to_tensor(img))\n",
        "  \n",
        "  return images"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8v4nJT3egF1"
      },
      "source": [
        "images = read_images(img_path)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "oF-JHP2degOs",
        "outputId": "01afb784-6a57-47de-9f2f-232be01913e3"
      },
      "source": [
        "\"\"\"\n",
        "image_content = tf.io.read_file(image_paths)\n",
        "mask_content = tf.io.read_file(mask_paths)\n",
        "\n",
        "images = tf.image.decode_jpeg(image_content, channels=self.channels[0])\n",
        "masks = tf.image.decode_jpeg(mask_content, channels=self.channels[1])\n",
        "\"\"\"\n",
        "\n",
        "@tf.function\n",
        "def load_image(filename):\n",
        "  raw = tf.io.read_file(filename)\n",
        "  image = tf.image.decode_png(raw, channels=3) #for mask channels = 1, decode_jpeg for jpg images\n",
        "  # the `print` executes during tracing.\n",
        "  print(\"Initial shape: \", image.shape)\n",
        "  image.set_shape([28, 28, 3])\n",
        "  print(\"Final shape: \", image.shape)\n",
        "  return image"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimage_content = tf.io.read_file(image_paths)\\nmask_content = tf.io.read_file(mask_paths)\\n\\nimages = tf.image.decode_jpeg(image_content, channels=self.channels[0])\\nmasks = tf.image.decode_jpeg(mask_content, channels=self.channels[1])\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWiG9T5DpqbB",
        "outputId": "21f463f5-9f40-40bb-edf5-f2d494eaa40b"
      },
      "source": [
        "!pip install tensorflow_addons"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n",
            "\r\u001b[K     |▌                               | 10kB 19.9MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 22.2MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 23.1MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 24.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51kB 24.4MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 25.6MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71kB 25.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81kB 26.3MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92kB 26.8MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102kB 27.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 112kB 27.3MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122kB 27.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133kB 27.3MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 143kB 27.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153kB 27.3MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163kB 27.3MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 174kB 27.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184kB 27.3MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 194kB 27.3MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 204kB 27.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215kB 27.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 225kB 27.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 235kB 27.3MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245kB 27.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 256kB 27.3MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 266kB 27.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276kB 27.3MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 286kB 27.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296kB 27.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 307kB 27.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317kB 27.3MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 327kB 27.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337kB 27.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 348kB 27.3MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 358kB 27.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 368kB 27.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 378kB 27.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 389kB 27.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 399kB 27.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 409kB 27.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 419kB 27.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 430kB 27.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 440kB 27.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 450kB 27.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 460kB 27.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 471kB 27.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 481kB 27.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 491kB 27.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 501kB 27.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 512kB 27.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 522kB 27.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 532kB 27.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 542kB 27.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 552kB 27.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 563kB 27.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 573kB 27.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 583kB 27.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 593kB 27.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 604kB 27.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 614kB 27.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 624kB 27.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 634kB 27.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 645kB 27.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 655kB 27.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 665kB 27.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 675kB 27.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 686kB 27.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN_-LYB0pqdK"
      },
      "source": [
        "import tensorflow_addons as tfa"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zJXWnvwpqf4"
      },
      "source": [
        "def blur(image, label):\n",
        "  image = tfa.image.gaussian_filter2d(image=image, filter_shape=(11, 11), sigma=0.8)\n",
        "  return image, label"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmyXnNyrzTI-"
      },
      "source": [
        "raw = tf.io.read_file(\"./001.png\")\n",
        "mask = tf.image.decode_png(raw, channels=1)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maivG3rq2V4T",
        "outputId": "7b4ac894-70c4-460a-df1c-1d07795404e6"
      },
      "source": [
        "mask = tf.reshape(mask, [mask.shape[0], mask.shape[1]])\n",
        "mask"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4000, 6000), dtype=uint8, numpy=\n",
              "array([[ 0,  0,  0, ...,  0,  0,  0],\n",
              "       [ 0,  0,  0, ...,  0,  0,  0],\n",
              "       [ 0,  0,  0, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [ 0,  0, 70, ...,  0,  0,  0],\n",
              "       [ 0,  0, 70, ...,  0,  0,  0],\n",
              "       [ 0,  0,  0, ...,  0,  0,  0]], dtype=uint8)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WX_QOhXG7YsP",
        "outputId": "cd63e7a7-1906-42e7-fb49-a752a02bfd4c"
      },
      "source": [
        "np.argmax(mask, axis=1)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3727, 3619,    4, ..., 1832, 1831,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo4quupU2YQZ"
      },
      "source": [
        "label = tf.one_hot(mask, 3)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EagTOEVW3pZJ",
        "outputId": "283ee382-4eef-4b01-df8f-62af973c4575"
      },
      "source": [
        "label"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              "array([[0., 0., 0.],\n",
              "       [0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmBsx8c13qd5"
      },
      "source": [
        "def load_masks(path, num_of_classes):\n",
        "\n",
        "  masks = []\n",
        "  for mask_path in os.listdir(path):\n",
        "    url = os.path.join(path, mask_path)\n",
        "    raw = tf.io.read_file(url)\n",
        "    mask = tf.image.decode_png(raw, channels=1)\n",
        "    mask = tf.reshape(mask, [mask.shape[0], mask.shape[1]])\n",
        "    mask = tf.one_hot(mask, num_of_classes)\n",
        "    masks.append(mask)\n",
        "  \n",
        "  return masks"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPQxzBIXEvXS"
      },
      "source": [
        "def load_masks_mat(path, num_of_classes):\n",
        "\n",
        "  masks = []\n",
        "  for mask_path in os.listdir(path):\n",
        "    url = os.path.join(path, mask_path)\n",
        "    mask_file = io.loadmat(url)\n",
        "    mask = tf.convert_to_tensor(mask_file['groundtruth'])\n",
        "    mask = tf.one_hot(mask, num_of_classes)\n",
        "    masks.append(mask)\n",
        "  \n",
        "  return masks"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5TAIE-W6Hka"
      },
      "source": [
        "masks = load_masks_mat(mask_path, 4)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzN4rGUt6WKP",
        "outputId": "818399d0-04ae-4420-98a7-6c9a30285d33"
      },
      "source": [
        "print(masks[0].shape)\n",
        "print(images[0].shape)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(827, 550, 4)\n",
            "(819, 550, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrqUd0DeEFoE"
      },
      "source": [
        "def resize_image(image):\n",
        "     image = tf.cast(image, tf.float32)\n",
        "     # scale values to [0,1]\n",
        "     image = image/255.0\n",
        "     # resize image\n",
        "     image = tf.image.resize(image, (128,128))\n",
        "     return image "
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vTZYI--EFrt"
      },
      "source": [
        "def resize_mask(mask):\n",
        "     mask = tf.image.resize(mask, (128,128))\n",
        "     mask = tf.cast(mask, tf.uint8)\n",
        "     return mask "
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK_T8A4dEKf5"
      },
      "source": [
        "x = [resize_image(i) for i in images]\n",
        "y = [resize_mask(m) for m in masks]"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwQBFEQGEYbt",
        "outputId": "6ef690b9-01ef-41a1-8f78-20b8de07e3a7"
      },
      "source": [
        "print(x[0].shape)\n",
        "print(y[0].shape)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 128, 3)\n",
            "(128, 128, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJh94WDr6osn"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_X, val_X,train_y, val_y = train_test_split(X,y, \n",
        "                                                 test_size=0.2, \n",
        "                                                 random_state=0\n",
        "                                                )\n",
        "train_X = tf.data.Dataset.from_tensor_slices(train_X)\n",
        "val_X = tf.data.Dataset.from_tensor_slices(val_X)\n",
        "train_y = tf.data.Dataset.from_tensor_slices(train_y)\n",
        "val_y = tf.data.Dataset.from_tensor_slices(val_y)\n",
        "train_X.element_spec, train_y.element_spec, val_X.element_spec, val_y.element_spec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a47RKvpADt5q"
      },
      "source": [
        "train = tf.data.Dataset.zip((train_X, train_y))\n",
        "val = tf.data.Dataset.zip((val_X, val_y)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o50SF-CDDt8E"
      },
      "source": [
        "def brightness(img, mask):\n",
        "     img = tf.image.adjust_brightness(img, 0.1)\n",
        "     return img, mask\n",
        " \n",
        " def gamma(img, mask):\n",
        "     img = tf.image.adjust_gamma(img, 0.1)\n",
        "     return img, mask\n",
        "\n",
        " def hue(img, mask):\n",
        "     img = tf.image.adjust_hue(img, -0.1)\n",
        "     return img, mask\n",
        "\n",
        " def crop(img, mask):\n",
        "     img = tf.image.central_crop(img, 0.7)\n",
        "     img = tf.image.resize(img, (128,128))\n",
        "     mask = tf.image.central_crop(mask, 0.7)\n",
        "     mask = tf.image.resize(mask, (128,128))\n",
        "     mask = tf.cast(mask, tf.uint8)\n",
        "     return img, mask\n",
        "\n",
        " def flip_hori(img, mask):\n",
        "     img = tf.image.flip_left_right(img)\n",
        "     mask = tf.image.flip_left_right(mask)\n",
        "     return img, mask\n",
        "\n",
        " def flip_vert(img, mask):\n",
        "     img = tf.image.flip_up_down(img)\n",
        "     mask = tf.image.flip_up_down(mask)\n",
        "     return img, mask\n",
        "\n",
        " def rotate(img, mask):\n",
        "     img = tf.image.rot90(img)\n",
        "     mask = tf.image.rot90(mask)\n",
        "     return img, mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILj5F2O-GrmH"
      },
      "source": [
        "# perform augmentation on train data only\n",
        " a = train.map(brightness)\n",
        " b = train.map(gamma)\n",
        " c = train.map(hue)\n",
        " d = train.map(crop)\n",
        " e = train.map(flip_hori)\n",
        " f = train.map(flip_vert)\n",
        " g = train.map(rotate)\n",
        "\n",
        " train = train.concatenate(a)\n",
        " train = train.concatenate(b)\n",
        " train = train.concatenate(c)\n",
        " train = train.concatenate(d)\n",
        " train = train.concatenate(e)\n",
        " train = train.concatenate(f)\n",
        " train = train.concatenate(g)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Gtn4gVRGvuf"
      },
      "source": [
        "BATCH = 64\n",
        "AT = tf.data.AUTOTUNE\n",
        "BUFFER = 1000\n",
        "STEPS_PER_EPOCH = 800//BATCH\n",
        "VALIDATION_STEPS = 200//BATCH\n",
        "train = train.cache().shuffle(BUFFER).batch(BATCH).repeat()\n",
        "train = train.prefetch(buffer_size=AT)\n",
        "val = val.batch(BATCH) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}